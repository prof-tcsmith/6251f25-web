<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 5: Classification & Logistic Regression</title>
    
    <!-- Reveal.js CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/theme/white.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/monokai.css">
    
    <!-- Common slide styles -->
    <link rel="stylesheet" href="../common-slides.css">
    
    <!-- Page-specific styles if needed -->
    <style>
        /* Confusion matrix styling */
        .confusion-matrix {
            margin: 20px auto;
            border-collapse: collapse;
            font-size: 0.8em;
        }
        
        .confusion-matrix td, .confusion-matrix th {
            border: 2px solid #333;
            padding: 15px;
            text-align: center;
            min-width: 100px;
        }
        
        .confusion-matrix th {
            background: linear-gradient(135deg, #1e3a5f 0%, #4a90e2 100%);
            color: white;
            font-weight: bold;
        }
        
        .confusion-matrix .tp {
            background-color: rgba(39, 174, 96, 0.3);
        }
        
        .confusion-matrix .tn {
            background-color: rgba(39, 174, 96, 0.3);
        }
        
        .confusion-matrix .fp {
            background-color: rgba(231, 76, 60, 0.3);
        }
        
        .confusion-matrix .fn {
            background-color: rgba(231, 76, 60, 0.3);
        }
        
        /* Metric cards */
        .metric-card {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.05) 0%, rgba(118, 75, 162, 0.05) 100%);
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 15px;
            margin: 10px;
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .metric-card h4 {
            color: #1e3a5f;
            margin: 0 0 10px 0;
            font-size: 0.9em;
        }
        
        .metric-card .formula {
            background: #f8f9fa;
            padding: 8px;
            border-radius: 4px;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.7em;
            margin: 10px 0;
        }
        
        .metric-card .value {
            font-size: 1.5em;
            font-weight: bold;
            color: #4a90e2;
        }
        
        /* ROC curve container */
        .roc-container {
            text-align: center;
            margin: 20px 0;
        }
        
        /* Business case styling */
        .business-case {
            background: rgba(243, 156, 18, 0.05);
            border-left: 4px solid #f39c12;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        
        .business-case h4 {
            color: #1e3a5f;
            margin-top: 0;
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">
            
            <!-- Title Slide -->
            <section>
                <h1>Classification & Logistic Regression</h1>
                <h3 style="border: none; text-align: center; color: #666;">From Predictions to Decisions</h3>
                <p style="text-align: center; font-style: italic; color: #888;">Binary Classification, Model Evaluation, and Business Applications</p>
                <p style="text-align: center; margin-top: 50px;">
                    <strong>ISM6251 | Week 5</strong><br>
                    Classification Models ‚Ä¢ Confusion Matrices ‚Ä¢ Evaluation Metrics ‚Ä¢ Logistic Regression
                </p>
            </section>

            <!-- Topic Overview Hierarchy -->
            <section>
                <h2>Week 5: Classification & Logistic Regression - Topic Hierarchy</h2>
                
                <!-- Learning Path at the top -->
                <div style="padding: 12px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 8px; margin-bottom: 15px;">
                    <p style="font-size: 1em; text-align: center; margin: 0; color: white; font-weight: bold;">
                        Learning Path: Classification Concepts ‚Üí Evaluation Metrics ‚Üí Logistic Regression ‚Üí Business Applications
                    </p>
                </div>
                
                <!-- Two-column ASCII tree layout -->
                <div style="display: flex; gap: 20px; height: 450px;">
                    <!-- Left Column -->
                    <div style="flex: 1; background: #f8f9fa; padding: 30px 20px; border-radius: 10px; font-family: 'Courier New', monospace; font-size: 0.65em; line-height: 1.5; height: 100%;">
                        <pre style="margin: 0; color: #2c3e50; height: 430px !important; overflow-y: auto !important; max-height: none !important;">
<strong style="color: #e74c3c;">CLASSIFICATION: FROM PREDICTIONS TO DECISIONS</strong>

<strong style="color: #3498db;">üìö Learning Objectives</strong>
‚îú‚îÄ‚îÄ Regression vs Classification
‚îú‚îÄ‚îÄ Confusion Matrices
‚îú‚îÄ‚îÄ Evaluation Metrics
‚îú‚îÄ‚îÄ Logistic Regression Mathematics
‚îú‚îÄ‚îÄ Business Applications
‚îú‚îÄ‚îÄ Metric Trade-offs
‚îî‚îÄ‚îÄ Class Imbalance Handling

<strong style="color: #9b59b6;">üéØ Part 1: Introduction to Classification</strong>
‚îú‚îÄ‚îÄ Classification vs Regression
‚îÇ   ‚îú‚îÄ‚îÄ Continuous ‚Üí Categorical
‚îÇ   ‚îú‚îÄ‚îÄ Probabilities ‚Üí Classes
‚îÇ   ‚îî‚îÄ‚îÄ Decision Boundaries
‚îú‚îÄ‚îÄ Types of Classification
‚îÇ   ‚îú‚îÄ‚îÄ Binary Classification
‚îÇ   ‚îú‚îÄ‚îÄ Multi-class Classification
‚îÇ   ‚îî‚îÄ‚îÄ Multi-label Classification
‚îî‚îÄ‚îÄ Business Applications
    ‚îú‚îÄ‚îÄ Customer Churn Prediction
    ‚îú‚îÄ‚îÄ Fraud Detection
    ‚îú‚îÄ‚îÄ Medical Diagnosis
    ‚îú‚îÄ‚îÄ Credit Risk Assessment
    ‚îî‚îÄ‚îÄ Marketing Response

<strong style="color: #e67e22;">üìä Part 2: Binary Classification Fundamentals</strong>
‚îú‚îÄ‚îÄ Classification Outcomes
‚îÇ   ‚îú‚îÄ‚îÄ True Positives (TP)
‚îÇ   ‚îú‚îÄ‚îÄ True Negatives (TN)
‚îÇ   ‚îú‚îÄ‚îÄ False Positives (FP) - Type I Error
‚îÇ   ‚îî‚îÄ‚îÄ False Negatives (FN) - Type II Error
‚îú‚îÄ‚îÄ The Confusion Matrix
‚îÇ   ‚îú‚îÄ‚îÄ 2√ó2 Matrix Structure
‚îÇ   ‚îú‚îÄ‚îÄ Reading the Matrix
‚îÇ   ‚îî‚îÄ‚îÄ Business Interpretation
‚îî‚îÄ‚îÄ Example: Customer Churn
    ‚îú‚îÄ‚îÄ Correctly Predicted Churners
    ‚îú‚îÄ‚îÄ Correctly Predicted Stayers
    ‚îú‚îÄ‚îÄ False Alarms
    ‚îî‚îÄ‚îÄ Missed Churners
                        </pre>
                    </div>
                    
                    <!-- Right Column -->
                    <div style="flex: 1; background: #f8f9fa; padding: 30px 20px; border-radius: 10px; font-family: 'Courier New', monospace; font-size: 0.65em; line-height: 1.5; height: 100%;">
                        <pre style="margin: 0; color: #2c3e50; height: 430px !important; overflow-y: auto !important; max-height: none !important;">
<strong style="color: #16a085;">üìà Part 3: Classification Metrics</strong>
‚îú‚îÄ‚îÄ Basic Metrics
‚îÇ   ‚îú‚îÄ‚îÄ Accuracy = (TP + TN) / Total
‚îÇ   ‚îú‚îÄ‚îÄ Error Rate = 1 - Accuracy
‚îÇ   ‚îî‚îÄ‚îÄ Baseline Performance
‚îú‚îÄ‚îÄ Precision & Recall
‚îÇ   ‚îú‚îÄ‚îÄ Precision = TP / (TP + FP)
‚îÇ   ‚îú‚îÄ‚îÄ Recall = TP / (TP + FN)
‚îÇ   ‚îú‚îÄ‚îÄ F1-Score = 2PR / (P + R)
‚îÇ   ‚îî‚îÄ‚îÄ Trade-off Considerations
‚îú‚îÄ‚îÄ Business Context Metrics
‚îÇ   ‚îú‚îÄ‚îÄ Cost-Sensitive Evaluation
‚îÇ   ‚îú‚îÄ‚îÄ Profit Curves
‚îÇ   ‚îî‚îÄ‚îÄ Lift Charts
‚îî‚îÄ‚îÄ Choosing the Right Metric
    ‚îú‚îÄ‚îÄ Balanced Classes ‚Üí Accuracy
    ‚îú‚îÄ‚îÄ Rare Events ‚Üí Precision/Recall
    ‚îî‚îÄ‚îÄ Business Costs ‚Üí Custom Metrics

<strong style="color: #d35400;">üîÆ Part 4: Logistic Regression</strong>
‚îú‚îÄ‚îÄ Mathematical Foundation
‚îÇ   ‚îú‚îÄ‚îÄ Sigmoid Function: œÉ(z) = 1/(1+e^-z)
‚îÇ   ‚îú‚îÄ‚îÄ Log Odds (Logit)
‚îÇ   ‚îú‚îÄ‚îÄ Maximum Likelihood Estimation
‚îÇ   ‚îî‚îÄ‚îÄ Gradient Descent Optimization
‚îú‚îÄ‚îÄ Model Interpretation
‚îÇ   ‚îú‚îÄ‚îÄ Coefficient Interpretation
‚îÇ   ‚îú‚îÄ‚îÄ Odds Ratios
‚îÇ   ‚îú‚îÄ‚îÄ Probability Thresholds
‚îÇ   ‚îî‚îÄ‚îÄ Decision Boundaries
‚îî‚îÄ‚îÄ Implementation in Python
    ‚îú‚îÄ‚îÄ Data Preparation
    ‚îú‚îÄ‚îÄ <span style="background: #fff3cd; padding: 1px;">‚ö†Ô∏è Feature Scaling</span>
    ‚îú‚îÄ‚îÄ Model Training
    ‚îú‚îÄ‚îÄ Probability Prediction
    ‚îî‚îÄ‚îÄ Threshold Tuning

<strong style="color: #27ae60;">‚öñÔ∏è Part 5: Advanced Topics</strong>
‚îú‚îÄ‚îÄ Class Imbalance
‚îÇ   ‚îú‚îÄ‚îÄ Detection Strategies
‚îÇ   ‚îú‚îÄ‚îÄ Resampling (Over/Under)
‚îÇ   ‚îú‚îÄ‚îÄ SMOTE
‚îÇ   ‚îú‚îÄ‚îÄ Class Weights
‚îÇ   ‚îî‚îÄ‚îÄ Threshold Adjustment
‚îú‚îÄ‚îÄ ROC Curve & AUC
‚îÇ   ‚îú‚îÄ‚îÄ TPR vs FPR Trade-off
‚îÇ   ‚îú‚îÄ‚îÄ Area Under Curve
‚îÇ   ‚îú‚îÄ‚îÄ Model Comparison
‚îÇ   ‚îî‚îÄ‚îÄ Threshold Selection
‚îî‚îÄ‚îÄ Multi-class Classification
    ‚îú‚îÄ‚îÄ One-vs-Rest
    ‚îú‚îÄ‚îÄ One-vs-One
    ‚îî‚îÄ‚îÄ Softmax Regression

<strong style="color: #c0392b;">üíº Part 6: Business Applications</strong>
‚îú‚îÄ‚îÄ Credit Card Fraud Detection
‚îÇ   ‚îú‚îÄ‚îÄ Extreme Imbalance (0.17%)
‚îÇ   ‚îú‚îÄ‚îÄ Cost Matrix Analysis
‚îÇ   ‚îî‚îÄ‚îÄ Precision vs Coverage
‚îú‚îÄ‚îÄ Best Practices
‚îÇ   ‚îú‚îÄ‚îÄ Cross-Validation
‚îÇ   ‚îú‚îÄ‚îÄ Stratified Sampling
‚îÇ   ‚îú‚îÄ‚îÄ Ensemble Methods
‚îÇ   ‚îî‚îÄ‚îÄ Model Monitoring
‚îî‚îÄ‚îÄ Key Takeaways
    ‚îú‚îÄ‚îÄ No Single Best Metric
    ‚îú‚îÄ‚îÄ Context Determines Choice
    ‚îú‚îÄ‚îÄ Trade-offs Are Inevitable
    ‚îî‚îÄ‚îÄ Next: Decision Trees
                        </pre>
                    </div>
                </div>
            </section>

            <!-- Learning Objectives -->
            <section>
                <h2>Learning Objectives</h2>
                <div class="info-box">
                    <p><strong>By the end of this session, you will be able to:</strong></p>
                </div>
                <ul>
                    <li>Understand the difference between regression and classification problems</li>
                    <li>Build and interpret confusion matrices for binary classifiers</li>
                    <li>Calculate and interpret key evaluation metrics (accuracy, precision, recall, F1-score)</li>
                    <li>Understand the mathematics and intuition behind logistic regression</li>
                    <li>Apply logistic regression to real business problems</li>
                    <li>Make informed decisions about metric trade-offs in business contexts</li>
                    <li>Handle class imbalance and understand its impact on model performance</li>
                </ul>
            </section>

            <!-- Part 1: Introduction to Classification -->
            <section>
                <section>
                    <h2>Part 1: Introduction to Classification</h2>
                    <h3>Moving from Continuous to Categorical Predictions</h3>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Regression vs Classification</h4>
                            <div class="info-box">
                                <strong>Regression:</strong> Predicts continuous values<br>
                                ‚Ä¢ Sales revenue: $125,432<br>
                                ‚Ä¢ Temperature: 72.5¬∞F<br>
                                ‚Ä¢ Stock price: $148.92
                            </div>
                            <div class="success-box">
                                <strong>Classification:</strong> Predicts discrete categories<br>
                                ‚Ä¢ Customer will churn: Yes/No<br>
                                ‚Ä¢ Email is spam: Spam/Not Spam<br>
                                ‚Ä¢ Transaction is fraud: Fraud/Legitimate
                            </div>
                        </div>
                        <div class="column-50">
                            <h4>Types of Classification</h4>
                            <ul>
                                <li><strong>Binary Classification:</strong> Two classes
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>Customer churns or stays</li>
                                        <li>Loan defaults or repaid</li>
                                        <li>Product defective or good</li>
                                    </ul>
                                </li>
                                <li><strong>Multi-class Classification:</strong> Multiple classes
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>Customer segment (A, B, C, D)</li>
                                        <li>Product category classification</li>
                                        <li>Risk level (Low, Medium, High)</li>
                                    </ul>
                                </li>
                            </ul>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Business Applications of Classification</h2>
                    <div class="columns">
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Marketing & Sales</h4>
                                <ul style="text-align: left; font-size: 0.8em;">
                                    <li>Lead scoring</li>
                                    <li>Customer churn prediction</li>
                                    <li>Cross-sell/up-sell targeting</li>
                                    <li>Campaign response prediction</li>
                                </ul>
                            </div>
                        </div>
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Finance & Risk</h4>
                                <ul style="text-align: left; font-size: 0.8em;">
                                    <li>Credit approval</li>
                                    <li>Fraud detection</li>
                                    <li>Default prediction</li>
                                    <li>Insurance claim classification</li>
                                </ul>
                            </div>
                        </div>
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Operations</h4>
                                <ul style="text-align: left; font-size: 0.8em;">
                                    <li>Quality control</li>
                                    <li>Equipment failure prediction</li>
                                    <li>Inventory categorization</li>
                                    <li>Supply chain risk assessment</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="warning-box">
                        <strong>Key Business Consideration:</strong> The cost of different types of errors varies dramatically across applications. 
                        Missing a fraudulent transaction might cost thousands, while flagging a legitimate transaction as fraud causes customer frustration.
                    </div>
                </section>
            </section>

            <!-- Part 2: Binary Classification & Confusion Matrix -->
            <section>
                <section>
                    <h2>Part 2: Understanding Binary Classification</h2>
                    <h3>The Foundation of Classification Metrics</h3>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Classification Output</h4>
                            <p>Binary classifiers make predictions in two forms:</p>
                            <ul>
                                <li><strong>Class Labels:</strong> Direct prediction (0 or 1, Yes or No)</li>
                                <li><strong>Probabilities:</strong> Likelihood of belonging to positive class (0.0 to 1.0)</li>
                            </ul>
                            <div class="info-box">
                                <strong>Decision Threshold:</strong><br>
                                Default threshold = 0.5<br>
                                ‚Ä¢ P(class=1) ‚â• 0.5 ‚Üí Predict 1<br>
                                ‚Ä¢ P(class=1) < 0.5 ‚Üí Predict 0
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python"># Example predictions
import numpy as np
from sklearn.linear_model import LogisticRegression

# Binary classification example
model = LogisticRegression()
model.fit(X_train, y_train)

# Get class predictions
y_pred = model.predict(X_test)
# Output: array([0, 1, 1, 0, 1, ...])

# Get probability predictions
y_proba = model.predict_proba(X_test)
# Output: array([[0.82, 0.18],  # 82% class 0
#                [0.31, 0.69],  # 69% class 1
#                [0.15, 0.85],  # 85% class 1
#                ...])

# Custom threshold
threshold = 0.7
y_custom = (y_proba[:, 1] >= threshold).astype(int)</code></pre>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>The Confusion Matrix</h2>
                    <div class="columns">
                        <div class="column-60">
                            <h4>Understanding Model Predictions</h4>
                            <table class="confusion-matrix">
                                <tr>
                                    <th colspan="2" rowspan="2" style="background: white; border: none;"></th>
                                    <th colspan="2">Predicted</th>
                                </tr>
                                <tr>
                                    <th>Negative (0)</th>
                                    <th>Positive (1)</th>
                                </tr>
                                <tr>
                                    <th rowspan="2" style="writing-mode: vertical-lr;">Actual</th>
                                    <th>Negative (0)</th>
                                    <td class="tn"><strong>True Negative (TN)</strong><br>Correctly predicted negative</td>
                                    <td class="fp"><strong>False Positive (FP)</strong><br>Type I Error<br>(False Alarm)</td>
                                </tr>
                                <tr>
                                    <th>Positive (1)</th>
                                    <td class="fn"><strong>False Negative (FN)</strong><br>Type II Error<br>(Missed Detection)</td>
                                    <td class="tp"><strong>True Positive (TP)</strong><br>Correctly predicted positive</td>
                                </tr>
                            </table>
                        </div>
                        <div class="column-40">
                            <h4>Business Interpretation</h4>
                            <div class="success-box">
                                <strong>Correct Predictions:</strong><br>
                                ‚Ä¢ <strong>TN:</strong> Customer stayed (predicted stay)<br>
                                ‚Ä¢ <strong>TP:</strong> Customer churned (predicted churn)
                            </div>
                            <div class="danger-box">
                                <strong>Errors & Their Costs:</strong><br>
                                ‚Ä¢ <strong>FP:</strong> Offered retention discount unnecessarily<br>
                                ‚Ä¢ <strong>FN:</strong> Lost customer without intervention
                            </div>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Confusion Matrix Example: Customer Churn</h2>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Scenario: Predicting Customer Churn</h4>
                            <table class="confusion-matrix">
                                <tr>
                                    <th colspan="2" rowspan="2" style="background: white; border: none;"></th>
                                    <th colspan="2">Predicted</th>
                                </tr>
                                <tr>
                                    <th>Will Stay</th>
                                    <th>Will Churn</th>
                                </tr>
                                <tr>
                                    <th rowspan="2" style="writing-mode: vertical-lr;">Actual</th>
                                    <th>Stayed</th>
                                    <td class="tn"><strong>850</strong><br>No action needed</td>
                                    <td class="fp"><strong>50</strong><br>Unnecessary retention offer<br>Cost: $50 √ó $100 = $5,000</td>
                                </tr>
                                <tr>
                                    <th>Churned</th>
                                    <td class="fn"><strong>30</strong><br>Lost customers<br>Cost: 30 √ó $1,000 = $30,000</td>
                                    <td class="tp"><strong>70</strong><br>Successfully retained<br>Saved: 70 √ó $900 = $63,000</td>
                                </tr>
                            </table>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python">from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Generate confusion matrix
cm = confusion_matrix(y_actual, y_predicted)

# Visualize with heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', 
            cmap='Blues', cbar=False,
            xticklabels=['Stay', 'Churn'],
            yticklabels=['Stay', 'Churn'])
plt.title('Customer Churn Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Business impact calculation
tn, fp, fn, tp = cm.ravel()
retention_cost = 100  # Cost of retention offer
customer_value = 1000  # Lost revenue from churn

false_positive_cost = fp * retention_cost
false_negative_cost = fn * customer_value
total_cost = false_positive_cost + false_negative_cost

print(f"Cost of false positives: ${false_positive_cost:,}")
print(f"Cost of false negatives: ${false_negative_cost:,}")
print(f"Total error cost: ${total_cost:,}")</code></pre>
                        </div>
                    </div>
                </section>
            </section>

            <!-- Part 3: Evaluation Metrics -->
            <section>
                <section>
                    <h2>Part 3: Classification Metrics</h2>
                    <h3>Measuring Model Performance</h3>
                    <div class="columns">
                        <div class="column-50">
                            <div class="metric-card">
                                <h4>Accuracy</h4>
                                <div class="formula">
                                    Accuracy = (TP + TN) / (TP + TN + FP + FN)
                                </div>
                                <p style="font-size: 0.8em;">Overall correctness of the model</p>
                                <div class="warning-box" style="font-size: 0.7em; text-align: left;">
                                    <strong>Limitation:</strong> Misleading with imbalanced classes
                                </div>
                            </div>
                            
                            <div class="metric-card">
                                <h4>Precision</h4>
                                <div class="formula">
                                    Precision = TP / (TP + FP)
                                </div>
                                <p style="font-size: 0.8em;">Of all positive predictions, how many were correct?</p>
                                <div class="info-box" style="font-size: 0.7em; text-align: left;">
                                    <strong>Focus:</strong> Minimizing false positives
                                </div>
                            </div>
                        </div>
                        <div class="column-50">
                            <div class="metric-card">
                                <h4>Recall (Sensitivity)</h4>
                                <div class="formula">
                                    Recall = TP / (TP + FN)
                                </div>
                                <p style="font-size: 0.8em;">Of all actual positives, how many did we catch?</p>
                                <div class="info-box" style="font-size: 0.7em; text-align: left;">
                                    <strong>Focus:</strong> Minimizing false negatives
                                </div>
                            </div>
                            
                            <div class="metric-card">
                                <h4>F1 Score</h4>
                                <div class="formula">
                                    F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
                                </div>
                                <p style="font-size: 0.8em;">Harmonic mean of precision and recall</p>
                                <div class="success-box" style="font-size: 0.7em; text-align: left;">
                                    <strong>Use when:</strong> Need balance between precision and recall
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Metrics in Business Context</h2>
                    <div class="business-case">
                        <h4>Example 1: Email Spam Detection</h4>
                        <div class="columns">
                            <div class="column-50">
                                <p><strong>High Precision Priority</strong></p>
                                <ul style="font-size: 0.8em;">
                                    <li>False Positive: Important email marked as spam</li>
                                    <li>False Negative: Spam reaches inbox</li>
                                    <li>Business Impact: FP is worse (missed important email)</li>
                                    <li>Target: High precision (>95%)</li>
                                </ul>
                            </div>
                            <div class="column-50 code-column">
                                <pre><code class="python"># Spam detection with high precision focus
from sklearn.metrics import classification_report

# Adjust threshold for higher precision
threshold = 0.8  # Higher threshold
y_pred_high_precision = (y_proba[:, 1] >= threshold)

print(classification_report(y_test, y_pred_high_precision,
                          target_names=['Ham', 'Spam']))</code></pre>
                            </div>
                        </div>
                    </div>
                    
                    <div class="business-case">
                        <h4>Example 2: Disease Screening</h4>
                        <div class="columns">
                            <div class="column-50">
                                <p><strong>High Recall Priority</strong></p>
                                <ul style="font-size: 0.8em;">
                                    <li>False Positive: Healthy person gets more tests</li>
                                    <li>False Negative: Sick person goes undiagnosed</li>
                                    <li>Business Impact: FN is worse (missed diagnosis)</li>
                                    <li>Target: High recall (>99%)</li>
                                </ul>
                            </div>
                            <div class="column-50 code-column">
                                <pre><code class="python"># Disease screening with high recall focus
threshold = 0.2  # Lower threshold
y_pred_high_recall = (y_proba[:, 1] >= threshold)

# Calculate metrics
from sklearn.metrics import recall_score, precision_score

recall = recall_score(y_test, y_pred_high_recall)
precision = precision_score(y_test, y_pred_high_recall)

print(f"Recall: {recall:.2%}")  # Should be very high
print(f"Precision: {precision:.2%}")  # May be lower</code></pre>
                            </div>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>The Precision-Recall Trade-off</h2>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Understanding the Trade-off</h4>
                            <ul>
                                <li><strong>Increasing Precision:</strong>
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>Raise decision threshold</li>
                                        <li>More conservative predictions</li>
                                        <li>Fewer false positives</li>
                                        <li>But more false negatives</li>
                                    </ul>
                                </li>
                                <li><strong>Increasing Recall:</strong>
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>Lower decision threshold</li>
                                        <li>More aggressive predictions</li>
                                        <li>Fewer false negatives</li>
                                        <li>But more false positives</li>
                                    </ul>
                                </li>
                            </ul>
                            <div class="info-box">
                                <strong>Business Decision:</strong> Choose based on relative costs of FP vs FN errors
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python">from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# Calculate precision-recall curve
precision, recall, thresholds = precision_recall_curve(
    y_test, y_proba[:, 1])

# Plot the curve
plt.figure(figsize=(10, 6))
plt.plot(recall, precision, 'b-', linewidth=2)
plt.xlabel('Recall', fontsize=12)
plt.ylabel('Precision', fontsize=12)
plt.title('Precision-Recall Trade-off', fontsize=14)
plt.grid(True, alpha=0.3)

# Mark specific threshold points
for t in [0.3, 0.5, 0.7]:
    idx = np.argmin(np.abs(thresholds - t))
    plt.plot(recall[idx], precision[idx], 'ro', markersize=8)
    plt.annotate(f'Threshold={t:.1f}', 
                xy=(recall[idx], precision[idx]),
                xytext=(recall[idx]-0.1, precision[idx]+0.05))

plt.show()</code></pre>
                        </div>
                    </div>
                </section>
            </section>

            <!-- Part 4: Logistic Regression -->
            <section>
                <section>
                    <h2>Part 4: Logistic Regression</h2>
                    <h3>The Workhorse of Binary Classification</h3>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Why Not Linear Regression?</h4>
                            <ul>
                                <li>Linear regression predicts unbounded values</li>
                                <li>We need probabilities between 0 and 1</li>
                                <li>Linear regression assumes normal distribution of errors</li>
                                <li>Binary outcomes violate this assumption</li>
                            </ul>
                            
                            <h4>The Logistic Function</h4>
                            <div class="info-box">
                                <strong>Sigmoid Function:</strong><br>
                                <span style="font-family: monospace;">p = 1 / (1 + e^(-z))</span><br>
                                where z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python">import numpy as np
import matplotlib.pyplot as plt

# Visualize sigmoid function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

z = np.linspace(-10, 10, 100)
p = sigmoid(z)

plt.figure(figsize=(10, 6))
plt.plot(z, p, 'b-', linewidth=2, label='Sigmoid')
plt.axhline(y=0.5, color='r', linestyle='--', 
            alpha=0.5, label='Decision Boundary')
plt.xlabel('z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çôx‚Çô', fontsize=12)
plt.ylabel('Probability', fontsize=12)
plt.title('Logistic (Sigmoid) Function', fontsize=14)
plt.grid(True, alpha=0.3)
plt.legend()
plt.ylim(-0.05, 1.05)
plt.show()

# Properties
print("Key Properties:")
print(f"sigmoid(0) = {sigmoid(0):.3f}")
print(f"sigmoid(-‚àû) ‚Üí 0")
print(f"sigmoid(+‚àû) ‚Üí 1")</code></pre>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Logistic Regression Interpretation</h2>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Odds and Log-Odds</h4>
                            <div class="info-box">
                                <strong>Odds:</strong> p / (1 - p)<br>
                                ‚Ä¢ Probability of success vs failure<br>
                                ‚Ä¢ If p = 0.75, odds = 3:1
                            </div>
                            
                            <div class="info-box">
                                <strong>Log-Odds (Logit):</strong> ln(p / (1 - p))<br>
                                ‚Ä¢ Linear relationship with predictors<br>
                                ‚Ä¢ log-odds = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ...
                            </div>
                            
                            <h4>Coefficient Interpretation</h4>
                            <ul style="font-size: 0.8em;">
                                <li>Œ≤ represents change in log-odds</li>
                                <li>e^Œ≤ represents odds ratio</li>
                                <li>For Œ≤ = 0.693: e^0.693 = 2 (doubles the odds)</li>
                            </ul>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python"># Logistic Regression Example: Customer Churn
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import pandas as pd

# Sample features
features = ['tenure', 'monthly_charges', 'total_charges', 
           'num_services', 'has_contract']

# Fit model
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train[features])

model = LogisticRegression()
model.fit(X_scaled, y_train)

# Examine coefficients
coef_df = pd.DataFrame({
    'Feature': features,
    'Coefficient': model.coef_[0],
    'Odds_Ratio': np.exp(model.coef_[0])
})

print(coef_df.to_string())
print(f"\nIntercept: {model.intercept_[0]:.3f}")

# Interpretation example
print("\nInterpretation:")
print("If tenure coefficient = -0.5:")
print("‚Ä¢ Each additional month reduces log-odds by 0.5")
print("‚Ä¢ Odds ratio = e^(-0.5) = 0.606")
print("‚Ä¢ Odds of churn decrease by 39.4% per month")</code></pre>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Implementing Logistic Regression</h2>
                    <div class="columns">
                        <div class="column-50 code-column">
                            <h4>Model Training</h4>
                            <pre><code class="python">from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

# Prepare data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# Scale features (important for logistic regression)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train model with regularization
model = LogisticRegression(
    penalty='l2',      # L2 regularization
    C=1.0,            # Inverse regularization strength
    max_iter=1000,    # Maximum iterations
    random_state=42
)

model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)
y_proba = model.predict_proba(X_test_scaled)

# Evaluate
print(classification_report(y_test, y_pred))</code></pre>
                        </div>
                        <div class="column-50 code-column">
                            <h4>Model Interpretation</h4>
                            <pre><code class="python"># Feature importance analysis
import matplotlib.pyplot as plt

# Get feature importance (absolute coefficients)
importance = np.abs(model.coef_[0])
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': importance
}).sort_values('importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'][:10], 
         feature_importance['importance'][:10])
plt.xlabel('Absolute Coefficient Value')
plt.title('Top 10 Most Important Features')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# Probability distribution
plt.figure(figsize=(10, 6))
plt.hist(y_proba[y_test==0, 1], bins=30, alpha=0.5, 
         label='Actual Negative', color='blue')
plt.hist(y_proba[y_test==1, 1], bins=30, alpha=0.5, 
         label='Actual Positive', color='red')
plt.xlabel('Predicted Probability')
plt.ylabel('Frequency')
plt.title('Distribution of Predicted Probabilities')
plt.legend()
plt.axvline(x=0.5, color='black', linestyle='--', 
           label='Default Threshold')
plt.show()</code></pre>
                        </div>
                    </div>
                </section>
            </section>

            <!-- Part 5: Advanced Topics -->
            <section>
                <section>
                    <h2>Part 5: Handling Class Imbalance</h2>
                    <h3>When Classes Are Not Equal</h3>
                    <div class="columns">
                        <div class="column-50">
                            <h4>The Imbalance Problem</h4>
                            <ul>
                                <li>Many business problems have imbalanced classes:
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>Fraud detection: ~0.1% fraudulent</li>
                                        <li>Customer churn: ~5-10% churn</li>
                                        <li>Manufacturing defects: ~1% defective</li>
                                    </ul>
                                </li>
                                <li>Model tends to predict majority class</li>
                                <li>High accuracy but poor minority class recall</li>
                            </ul>
                            
                            <div class="warning-box">
                                <strong>Example:</strong> 99% accuracy in fraud detection might mean the model predicts "no fraud" for everything!
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python"># Strategies for handling imbalance

# 1. Class weight adjustment
model_weighted = LogisticRegression(
    class_weight='balanced',  # Automatically adjust
    random_state=42
)

# 2. Custom class weights
model_custom = LogisticRegression(
    class_weight={0: 1, 1: 10},  # 10x weight for minority
    random_state=42
)

# 3. Resampling techniques
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# Oversampling minority class
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Undersampling majority class
rus = RandomUnderSampler(random_state=42)
X_under, y_under = rus.fit_resample(X_train, y_train)

# 4. Threshold adjustment
# Instead of 0.5, use optimal threshold
from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]</code></pre>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>ROC Curve and AUC</h2>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Receiver Operating Characteristic</h4>
                            <ul>
                                <li><strong>ROC Curve:</strong> TPR vs FPR at all thresholds</li>
                                <li><strong>AUC:</strong> Area Under the Curve (0.5 to 1.0)</li>
                                <li><strong>Interpretation:</strong>
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>AUC = 0.5: Random guessing</li>
                                        <li>AUC = 0.7-0.8: Acceptable</li>
                                        <li>AUC = 0.8-0.9: Excellent</li>
                                        <li>AUC > 0.9: Outstanding</li>
                                    </ul>
                                </li>
                            </ul>
                            
                            <div class="success-box">
                                <strong>Advantage:</strong> AUC is threshold-independent and works well for imbalanced datasets
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python">from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, 
         label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, 
         linestyle='--', label='Random Classifier')

# Mark optimal point
optimal_idx = np.argmax(tpr - fpr)
plt.plot(fpr[optimal_idx], tpr[optimal_idx], 
         'ro', markersize=10, label='Optimal Threshold')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curve - Customer Churn Model', fontsize=14)
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.show()

print(f"Optimal threshold: {thresholds[optimal_idx]:.3f}")
print(f"TPR at optimal: {tpr[optimal_idx]:.3f}")
print(f"FPR at optimal: {fpr[optimal_idx]:.3f}")</code></pre>
                        </div>
                    </div>
                </section>
            </section>

            <!-- Part 6: Business Case Studies -->
            <section>
                <section>
                    <h2>Business Case Study: Credit Card Fraud Detection</h2>
                    <div class="columns">
                        <div class="column-50">
                            <h4>Business Context</h4>
                            <ul>
                                <li><strong>Problem:</strong> Detect fraudulent transactions</li>
                                <li><strong>Class Distribution:</strong> 0.17% fraud rate</li>
                                <li><strong>Business Costs:</strong>
                                    <ul style="font-size: 0.9em; margin-left: 20px;">
                                        <li>False Negative: Average fraud loss $1,200</li>
                                        <li>False Positive: Customer call $25 + friction</li>
                                    </ul>
                                </li>
                            </ul>
                            
                            <div class="business-case">
                                <h4>Optimal Strategy</h4>
                                <p><strong>Cost-Sensitive Learning:</strong></p>
                                <ul style="font-size: 0.8em;">
                                    <li>Weight ratio: 1200/25 = 48:1</li>
                                    <li>Focus on high recall (catch fraud)</li>
                                    <li>Accept lower precision (more false alarms)</li>
                                </ul>
                            </div>
                        </div>
                        <div class="column-50 code-column">
                            <pre><code class="python"># Fraud detection implementation
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# Load and prepare data
# Features: transaction_amount, merchant_risk, time_of_day, etc.

# Cost-sensitive model
fraud_model = RandomForestClassifier(
    n_estimators=100,
    class_weight={0: 1, 1: 48},  # Based on cost ratio
    random_state=42
)

fraud_model.fit(X_train, y_train)

# Evaluate with business metrics
y_pred = fraud_model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

# Calculate business impact
fraud_caught = tp * 1200  # Fraud prevented
false_alarms_cost = fp * 25  # Cost of false positives
fraud_missed = fn * 1200  # Fraud losses

roi = (fraud_caught - false_alarms_cost - fraud_missed)

print(f"Fraud prevented: ${fraud_caught:,.0f}")
print(f"False alarm costs: ${false_alarms_cost:,.0f}")
print(f"Fraud losses: ${fraud_missed:,.0f}")
print(f"Net benefit: ${roi:,.0f}")

# Precision at different recall levels
from sklearn.metrics import precision_recall_curve
p, r, t = precision_recall_curve(y_test, y_proba[:, 1])

for recall_target in [0.80, 0.90, 0.95]:
    idx = np.argmin(np.abs(r - recall_target))
    print(f"At {recall_target:.0%} recall: "
          f"precision = {p[idx]:.1%}, "
          f"threshold = {t[idx]:.3f}")</code></pre>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>Implementation Best Practices</h2>
                    <div class="columns">
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Data Preparation</h4>
                                <ul style="text-align: left; font-size: 0.7em;">
                                    <li>Handle missing values carefully</li>
                                    <li>Scale/normalize features</li>
                                    <li>Encode categorical variables</li>
                                    <li>Check for multicollinearity</li>
                                    <li>Create interaction terms if needed</li>
                                </ul>
                            </div>
                        </div>
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Model Development</h4>
                                <ul style="text-align: left; font-size: 0.7em;">
                                    <li>Start with logistic regression baseline</li>
                                    <li>Use cross-validation</li>
                                    <li>Apply regularization (L1/L2)</li>
                                    <li>Handle class imbalance</li>
                                    <li>Optimize threshold based on costs</li>
                                </ul>
                            </div>
                        </div>
                        <div class="column-33">
                            <div class="metric-card">
                                <h4>Business Integration</h4>
                                <ul style="text-align: left; font-size: 0.7em;">
                                    <li>Define success metrics upfront</li>
                                    <li>Calculate ROI/business impact</li>
                                    <li>Create monitoring dashboards</li>
                                    <li>Plan for model updates</li>
                                    <li>Document decision rationale</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="warning-box">
                        <strong>Remember:</strong> The best model isn't always the one with the highest accuracy. Consider business costs, interpretability, and implementation complexity.
                    </div>
                </section>
            </section>

            <!-- Summary -->
            <section>
                <h2>Key Takeaways</h2>
                <div class="columns">
                    <div class="column-50">
                        <h4>Classification Fundamentals</h4>
                        <ul>
                            <li>Classification predicts discrete categories, not continuous values</li>
                            <li>Binary classification is the foundation for more complex problems</li>
                            <li>Confusion matrix reveals all types of prediction errors</li>
                            <li>Different metrics optimize for different business objectives</li>
                        </ul>
                        
                        <h4>Logistic Regression</h4>
                        <ul>
                            <li>Uses sigmoid function to produce probabilities</li>
                            <li>Coefficients represent changes in log-odds</li>
                            <li>Interpretable and fast to train</li>
                            <li>Works well as a baseline model</li>
                        </ul>
                    </div>
                    <div class="column-50">
                        <h4>Evaluation Metrics</h4>
                        <ul>
                            <li><strong>Accuracy:</strong> Overall correctness (misleading if imbalanced)</li>
                            <li><strong>Precision:</strong> Minimize false positives</li>
                            <li><strong>Recall:</strong> Minimize false negatives</li>
                            <li><strong>F1 Score:</strong> Balance precision and recall</li>
                            <li><strong>AUC-ROC:</strong> Threshold-independent performance</li>
                        </ul>
                        
                        <h4>Business Considerations</h4>
                        <ul>
                            <li>Always consider the cost of different error types</li>
                            <li>Class imbalance requires special handling</li>
                            <li>Threshold optimization can improve business outcomes</li>
                            <li>Model interpretability matters for stakeholder buy-in</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Practice & Next Steps -->
            <section>
                <h2>Practice Exercises & Next Steps</h2>
                <div class="columns">
                    <div class="column-50">
                        <h4>This Week's Assignment</h4>
                        <div class="info-box">
                            <strong>Customer Churn Prediction</strong><br>
                            Build a logistic regression model to predict customer churn:
                            <ul style="font-size: 0.9em; margin-top: 10px;">
                                <li>Load and explore the telecom churn dataset</li>
                                <li>Prepare features and handle categorical variables</li>
                                <li>Build and evaluate logistic regression model</li>
                                <li>Calculate and interpret all metrics</li>
                                <li>Optimize threshold for business objectives</li>
                                <li>Create confusion matrix visualization</li>
                            </ul>
                        </div>
                    </div>
                    <div class="column-50">
                        <h4>Next Week: K-Nearest Neighbors</h4>
                        <div class="success-box">
                            <strong>Preview of Topics:</strong>
                            <ul style="font-size: 0.9em; margin-top: 10px;">
                                <li>Instance-based learning</li>
                                <li>Multi-class classification</li>
                                <li>Distance metrics</li>
                                <li>Feature scaling importance</li>
                                <li>Curse of dimensionality</li>
                            </ul>
                        </div>
                        
                        <h4>Resources</h4>
                        <ul style="font-size: 0.8em;">
                            <li>Scikit-learn documentation on logistic regression</li>
                            <li>Google's Machine Learning Crash Course</li>
                            <li>Business case studies on Kaggle</li>
                        </ul>
                    </div>
                </div>
            </section>

        </div>
    </div>

    <!-- Reveal.js Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/markdown/markdown.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/math/math.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/notes/notes.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/zoom/zoom.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.3.1/plugin/search/search.js"></script>
    
    <script>
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            center: false,
            slideNumber: 'c/t',
            transition: 'slide',
            backgroundTransition: 'fade',
            width: 1280,
            height: 720,
            margin: 0.05,
            
            plugins: [ 
                RevealMarkdown, 
                RevealHighlight, 
                RevealNotes,
                RevealZoom,
                RevealSearch,
                RevealMath.KaTeX
            ]
        });
    </script>
</body>
</html>